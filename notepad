perpetual notepad: i keep adding to this whenever.

april 9

i'm starting a machine learning course on coursera. this is like the third time i've started up, every time i quit midway. hopefully i dont quit

implemented better graphics, functions such as mathematical loops and effects into unlimited-bullets-festival

got touhou soundtrack: its better with all the bullet noises

april 10

	coursera machine learning notes:

		linear regression: finding the line that fits all the points

		functions at http://puu.sh/h90JM/a14f7baef7.png.

		cost function is the 1/2m thing

		m = number of training examples

		in the loop: i is the current training example

		h.theta(x(i)) is the same as theta.0 + theta.1*x(i).
		theta.1 is the slope, and x(i) is just the current x.

		The cost function: the average of the hypothesis(base and slope) differnce between the actual numbers.
		we are trying to make the cost function as low as possible.


	ideas for fixing up skyflower: make it more bullet-helly. minibosses that spam bullets everywhere, make the player hitbox smaller, add turrets that spray patterns everywhere, fix up the bosses to have more interesting patterns.

	stanford course:
		set: just a bunch of stuff in some kind of order, no duplicates
			hashset: no order
			multiply sets = returns things that are in both sets
		lexicon
		map: pairs with key/value: dictonary -> indexes are keys, can use brackets



	more coursera ml notes:

		gradient descent: keep moving in small steps until you reach the optimum

			alpha: how big the step is
			simultanieous update: find theta.0 and theta.1 with the same function, then update both for the next step.
			when its setting theta.j: it means it sets theta.0 and theta.1, because it loops as j.
			derivatives: at a certain point, the slope of the curve.
				FOR THE 3D: we take derivates of both theta.0 and theta.1 in the simultaneous update.

			remember how sometimes this can screw up if there are two local optima? well with our cost function theres only one, so its fine.

	whooo i got 5/5 on the quiz, maybe i'll actually pass the course this time :P

april 11:

	rip zero period at gunn, you will be remebered.

	online course list for a BS equivalent in CS: https://docs.google.com/spreadsheets/d/1_kdHrT8izbROJNaxGflpcZm2ivsjRGF8j1hMzl3b8O0/htmlview?usp=sharing&sle=true#

	coursera ml notes:

		matrices: like a 2d array of numbers. written as row x column.

			1 2
			3 4
			5 6

			thats a 3x2.

			R.31 = 5.

			speciaal R with the two lines = a matrix

		Vector: nx1 matrix.

		adding matrices: they have to be the same dimension. -> just add each corresponding one.

		scalar multiplication: multiply a matrix by a number. -> multiply each element by that number.

		matrix vector multiplication: take the first row and multiply it by the vector, then add that up. that is the corresponding element in the result.
			http://puu.sh/h9Yui/fc86586870.png

			columns in first matrix matches the rows in second matrix.

		using it for the hypothesis:
			prediction = DataMatrix x parameters

			[1 2100] x [ -40 0.25]   -> the -40 is theta.0, the 0.25 is theta.1
			[1 1416]



		matrix matrix multiplication: matrix vector multiplication for each column in the second matrix, and the results are put together in a new matrix.
			m by n X n by o -> m by o result.


			use it for when there are competing hypothesis: like the matrix x vector, but the multiple columns of the second vector are the different kinds of hypothesis.

		identity matrix: the diagonal starting from 0,0, then 1,1, etc = 1.

			multiplying any matrix by the identity matrix returns the same matrix.

		matrix inverse: if A is m by m matrix, and it has an inverse:
			A x A.-1 = A.-1 x A = A.
			no invrese = singular or degenarate.

		matrix transpose: rows are columns, columns are rows.


	4/5 on the quiz.

	whoo i'm organizing https://www.makeschool.com/shipathon

	finished problem "transform" on USCAO

	unlimited bullets factory: added in the "c" prefix for the "make" command on rotations: it carrys over the parent bullet's rotation;

	prep for writing an article on mitmproxy:

		how to hack simple apps using man in the middle

	changed the view-distance on Skyflower, and started renovation on the first boss.

		todo: make a logo.

		note: 4,500 unsynced changes! wow.



april 12

	coursera ml notes

		n = number of features

		x(i) = features of i'th training example

		x.j(i) = feature j in i'th training example

		multiple features hypothesis: h.theta = theta.0 + theta.1*x.1 .... + theta.n * x.n

			each x.n value is the influence that each feature has on the price.

		multiple feature gradient descent is also the same, just with many features. make sure to simul update.

		feature scaling: try to get all features to same scale of -1 to 1 by subtracting average and dividing by range.


	unlimited-bullets-factory: fixed some bug where loops would fail.

	pixel-rpg: enemies fire.

	USCAO: solved namenums.

april 13

	coursera continuted:

		if the alpha is too small, it goes really slow. if it's high, it screws up everything.

		test alpha: 0.001, 0.003, 0.01, ~x3 each time.

		polynomial regression:

			use a feature, as the square of something.

			> make sure to feature scale correctly!


	things to add to website:

		michael abehsera app

		the goose game

		civil war

		osu dj

		twisted fate

		random gunner / flash games

april 14

	coursera:

		normal equation: no choose alpha, no iteration, no feature scaling.

		gradient descent works better when there are a lot of features.

		normal equation needs to compute X'X, so lots of features means its slow.

		5/5 quiz thumbs up :)



	programming challenge for coursera machine learning! we doing this Matlab style.3


	x:[data data data]
	y:[result result result]

	theta[1,multiplier]

	okay so i solved up to the gradient descent and had problems with linear algebra so i had to look up help. shameful

	finally the matlab hw is done.


	added some new projects to website like osu-dj

	osu-dj: if you can't find the source, it goes into 420 mode.

april 15

	finished problem base conversion for usaco.

	stanford course was just some recursion stuff.

	osu-dj: making some improvements.

april 17

	dang i feel bad i skipped april 16. slept for like 10 hrs straight.

	BIG NEWS: SKYFLOWER GOT GREENLIT ON STEAM! WHOOOOOOOOOO

	i'm losing track of a bunch of things i need to do like boy scouts stuff

	skyflower changes:

		hitbox accuratley matches player

april 18:

	time to work a ton on skyflower.

		changes:

		patterns for first and second boss updated.

		lol


april 19:

	fixexd more bugs in skyflower:

		addec changes for the pickups, some other things too.

	worked a bit on the wwdc thing


april 20

	ayyyy 4/20

	did a bunch of experimenting to crack leaguesharp. cant inject rip in pepsi

april 21

	filmed footage for the skyflower

	coursera ml course notes:

		logistic regression: instead of linear regression, it classifies.

		the result is always between 0 and 1.

		0 is one option, 1 is the other. usually 0.5 is cutoff point for choosing.

		sigmoid function / logistic function: it asymptotes (closes but doesnt reach) 0 and 1.

			h.teta(x) = g(theta.transpose.x)
			g(z) = 1/(1+e^-z)

			http://puu.sh/hmsf3/ec656989be.png

		hypothesis result = the propability that result is 1.

		1 - the result = the prop that result is 0.

		you can make circles and stuff by using the theta parameter squared.


april 22

	reuploading skyflower gameplay to dropbox this time.

	wwdc: imported the Spring animation library to make things look prettier.


	LIST OF THINGS TO POLISH FOR SKYFLOWER
	hero selection
	holding [shift] shows hitboxes
	animations for getting items and powerups
	pause menu: adjust volume, shows items you havex
	fix Blessing bug...
	change animation for giant laser
	fix Pentagram boss lightning bustling
	//fix animations for players on suit guy but also everyone else
	AN EPIC BOSS ANIMATION SEQUENCE WHEN IT SPAWNS WHEN YOU GET IN RANGE.
	update item description
	high scores //do this with steam api
	//fix pentagram's arms not going off

	TUTORIAL!!!

	MULTIPLAYER bugfix!!


	skyflower:

		added sound effects and updated item descriptions

		fixed movescript polling every update.

april 23:

	did usaco problem: dualpal.


	coursera ML notes:

		logistic regression cant use the same cost funcion as linear regression because it would be non-convec.

		the new cost function:

			cost(h.theta.x,y) =
				if y is 1: -log(h.theta.x)
				if y is 0: -log(1 - h.theta.x)

			http://puu.sh/hoA6L/6bbab3d151.png
			http://puu.sh/hoAfz/55a2f1dc16.png

	skyflower:

		fixed blessing bug: now it deletes all powerups.

		fixed pentagram boss.


april 24:

	submitted wwdc app. glhf!

april 25:

	cleaned up githib repos.


april 26:

	rip april 15. i forgot to do stuf.

	edit: nvm i didnt

	PITCH FOR MAKEHACKS:

		have you ever finished a game and wished there was more?

		skyflower: randomly generation rougelike shooter.

		in skyflower, players collect items, powerups, and defeat enemies to reach the skies

		levels are completely generated from scratch every time you play through

		at this hackathon, i finshed the multiplayer portion, allowing up to four people to play.

		theres 5 worlds, each with a custom boss

		bosses follow a danmaku or bullet-hell style gameplay: with patterns and loops, intricate patterns that are challenging and nice to look at.

		items use an upgrade system: each one builds on the other

		pixel art: mimic arcade-style games

		3 classes

	gg i won

april 27:

	lefet my charger at shipathon, cant do anything today.

april 28:

	still no charger. did some pixel art at kevinfrans.deviantart.com

april 29:

	finally got charger and backed up

	stanford data abstractions:

		destructor: called when an object is destroyed

			syntax: ~Classname()

			used to free up memorys

		if you use the "new" keyword, then you have to delete it yourself

		linked data structures: each node holds data and a reference to the next one.

		pointers: memory adress of a variable.

			access address with &variable.

			hex numbes,  most occupy 4 bytes of memory.

			pointer with *variable.

			null pointer: points to 0.

			arrow operator: -> same as using a dot for calling a function but you use it on a pointer instead of an object.

			initialize a pointer with object initializer: it doesn't remove at the end of scope.

		struct: its like a class, but its just variable w/o functions.


		[WT!] biky pointers: funny video on points claymation

april 30:


	wasted time at gunn badminton match lol

	did usaco milk problem.


may 1:

	game idea: towers legacy. i put it in a new file file. [private sorry!]


may 2:

	started on skylines pixel art

	coursera ML notes:

		we have a way to compute the cost function, as well as the derivative.

		with that, we can use algoritms other than gradient descent such as conjugate descent, BGFS, or L-BFGS

			- these makes it not need to calculate alpha, and is faster:
			- however its more complicated

		often there are libraries that implement these algoritms

		logistic regression w/ multiclasses:

			ex: categorizing into one of many categories.

			one vs. all algoritm: assign each class as the positive class, and all the rest as negative.
			it can then find the propability that the result is 1,2,3, etc.
			whichever one has the highest propability, its the category that it belongs in.

		rip, 0/5 on the quiz. gotta redo this.

		got up to 3/5. redo again lol

may 3:

	got a lot of things to do:
		-skyflower build
		-uscao
		-coursera ML
		-email emotiv
		-email mgwu


	okay emails sent.

	coursera: finished the quizzes, and did programming hw.

	solved usaco barn1 on the first try, 2 pro.

	i actually finished everything on the checklist at 4 PM whooo
